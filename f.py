import streamlit as st
import openai
import os
from dotenv import load_dotenv

# Carregar vari√°veis de ambiente (para a API key)
load_dotenv()

# Configura√ß√£o da p√°gina
st.set_page_config(
    page_title="ChatBot IA",
    page_icon="ü§ñ",
    layout="wide"
)

# Configurar API key
openai.api_key = os.getenv("OPENAI_API_KEY")

# T√≠tulo principal
st.title("ChatBot IA")
st.markdown("---")

# Inicializar hist√≥rico de chat se n√£o existir
if "messages" not in st.session_state:
    st.session_state.messages = []

# Fun√ß√£o para obter resposta da OpenAI
def get_ai_response(prompt):
    try:
        response = openai.chat.completions.create(
            model="gpt-3.5-turbo",
            messages=[
                {"role": "system", "content": "Voc√™ √© um assistente √∫til e amig√°vel."},
                {"role": "user", "content": prompt}
            ]
        )
        return response.choices[0].message.content
    except Exception as e:
        return f"Erro: {str(e)}"

# Exibir mensagens anteriores
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

# Campo de entrada do usu√°rio
prompt = st.chat_input("Digite sua mensagem aqui...")

# Processar input do usu√°rio
if prompt:
    # Adicionar mensagem do usu√°rio ao hist√≥rico
    st.session_state.messages.append({"role": "user", "content": prompt})
    
    # Exibir mensagem do usu√°rio
    with st.chat_message("user"):
        st.markdown(prompt)
    
    # Obter resposta do assistente
    with st.chat_message("assistant"):
        with st.spinner("Pensando..."):
            response = get_ai_response(prompt)
            st.markdown(response)
    
    # Adicionar resposta do assistente ao hist√≥rico
    st.session_state.messages.append({"role": "assistant", "content": response})

# Bot√£o para limpar o hist√≥rico
if st.button("Limpar Conversa"):
    st.session_state.messages = []
    st.experimental_rerun()
